{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m3Rzi1i5Nn_"
      },
      "source": [
        "# Chapter 7 - Testing TinyML on Emulated Devices with Zephyr OS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0538tk5G5wS-"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 2.x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFH6sggj5gil"
      },
      "source": [
        "### Python libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eo9ladr5SZn7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from tensorflow.keras import datasets, layers, models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYE4IBmu5n4f"
      },
      "source": [
        "### Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_k_Cy76vT5x"
      },
      "outputs": [],
      "source": [
        "TF_MODEL=\"cifar10\"\n",
        "TFL_MODEL_FILE=\"cifar10.tflite\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyHTQZpU52sx"
      },
      "source": [
        "## Designing and training a tiny CIFAR-10 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_Nxb9sK58Yv"
      },
      "source": [
        "### Download the CIFAR-10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lq_52sZSSbAM"
      },
      "outputs": [],
      "source": [
        "(train_imgs, train_lbls), (test_imgs, test_lbls) = datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVd39YoE6FFP"
      },
      "source": [
        "### Normalize the pixel values between 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7GLj26eScvA"
      },
      "outputs": [],
      "source": [
        "train_imgs = train_imgs / 255.0\n",
        "test_imgs = test_imgs / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N29h2c26JnG"
      },
      "source": [
        "### Define a Python function to implement DWSC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7ZrLwf3U27n"
      },
      "outputs": [],
      "source": [
        "def separable_conv(input, ch, idx):\n",
        "    x = layers.DepthwiseConv2D((3,3), padding=\"same\", name='dwc0_dwsc'+str(idx))(input)\n",
        "    x = layers.BatchNormalization( name='bn0_dwsc'+str(idx))(x)\n",
        "    x = layers.Activation(\"relu\", name='act0_dwsc'+str(idx))(x)\n",
        "    x = layers.Conv2D(ch, (1,1), padding=\"same\", name='conv0_dwsc'+str(idx))(x)\n",
        "    x = layers.BatchNormalization(name='bn1_dwsc'+str(idx))(x)\n",
        "    return layers.Activation(\"relu\", name='act1_dwsc'+str(idx))(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOcNHfBp6Tji"
      },
      "source": [
        "### Design the convolution base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4inTH8mBWhON"
      },
      "outputs": [],
      "source": [
        "input = layers.Input((32,32,3))\n",
        "x = layers.Conv2D(16, (3, 3), padding='same', name='conv1')(input)\n",
        "x = layers.BatchNormalization(name='bn1')(x)\n",
        "x = layers.Activation(\"relu\", name='act1')(x)\n",
        "x = separable_conv(x, 24, 2)\n",
        "x = layers.MaxPooling2D((2, 2), name='pool1')(x)\n",
        "x = separable_conv(x, 48, 3)\n",
        "x = layers.MaxPooling2D((2, 2), name='pool2')(x)\n",
        "x = separable_conv(x, 96, 4)\n",
        "x = separable_conv(x, 192, 5)\n",
        "x = layers.MaxPooling2D((2, 2), name='pool3')(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29ypqd7F6aF3"
      },
      "source": [
        "### Design the classification head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXAVxY_C6gaB"
      },
      "outputs": [],
      "source": [
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = layers.Dense(10)(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyFyZoKg6hCA"
      },
      "source": [
        "### Generate the model and print its summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2xF5JV06oOK"
      },
      "outputs": [],
      "source": [
        "model = Model(input, x)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b44h7-vK6scm"
      },
      "source": [
        "### (Optional) Evaluate the tensor size for the intermediate tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3houi5ytOwI"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(dpi=100)\n",
        "\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "\n",
        "l_idx   = []\n",
        "l_sizes = []\n",
        "\n",
        "for layer in model.layers[1:]:\n",
        "  shape = layer.output_shape\n",
        "  shape = np.delete(shape, 0)\n",
        "  size  = np.prod(shape)\n",
        "  l_idx   = np.append(l_idx, layer.name)\n",
        "  l_sizes = np.append(l_sizes, size)\n",
        "\n",
        "ax.bar(l_idx, l_sizes)\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcDG3NpF7N6l"
      },
      "source": [
        "### Compile and train the model with 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vI1Lwnx3W2zH"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_imgs, train_lbls, epochs=10, \n",
        "                    validation_data=(test_imgs, test_lbls))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDdJojDC7TAd"
      },
      "source": [
        "### Save the TensorFlow model as SavedModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9K764BFQvQMd"
      },
      "outputs": [],
      "source": [
        "model.save(TF_MODEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ6heILv7YJm"
      },
      "source": [
        "## Evaluating the accuracy of the TFLite model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXbLjJivYnn4"
      },
      "source": [
        "### Select a few hundred of samples from the train dataset to calibrate the quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSAZguvzlXAC"
      },
      "outputs": [],
      "source": [
        "cifar_ds = tf.data.Dataset.from_tensor_slices(train_imgs).batch(1)\n",
        "def representative_data_gen():\n",
        "  for i_value in cifar_ds.take(100):\n",
        "    i_value_f32 = tf.dtypes.cast(i_value, tf.float32)\n",
        "    yield [i_value_f32]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_qNdaNrYzB2"
      },
      "source": [
        "### Initialize the TFLite converter to perform the 8-bit quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90KpsBtfvafA"
      },
      "outputs": [],
      "source": [
        "tfl_conv = tf.lite.TFLiteConverter.from_saved_model(TF_MODEL)\n",
        "tfl_conv.representative_dataset = tf.lite.RepresentativeDataset(representative_data_gen)\n",
        "tfl_conv.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tfl_conv.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "tfl_conv.inference_input_type = tf.int8\n",
        "tfl_conv.inference_output_type = tf.int8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu50iI6dZU0B"
      },
      "source": [
        "### Convert the model to TFLite file format and save it as .tflite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAIMeFoOvhel"
      },
      "outputs": [],
      "source": [
        "tfl_model = tfl_conv.convert()\n",
        "open(TFL_MODEL_FILE, \"wb\").write(tfl_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLfCt7EnZnCW"
      },
      "source": [
        "### Evaluate the model size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URcHnwt9rXLj"
      },
      "outputs": [],
      "source": [
        "print(len(tfl_model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWp3T8weZr9y"
      },
      "source": [
        "### Evaluate the accuracy of the quantized model using the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtEkxuDXwmVx"
      },
      "outputs": [],
      "source": [
        "# Initialize the TFLite interpreter\n",
        "tfl_inter = tf.lite.Interpreter(model_content=tfl_model)\n",
        "\n",
        "# Allocate the tensors\n",
        "tfl_inter.allocate_tensors()\n",
        "\n",
        "# Get input/output layer information\n",
        "i_details = tfl_inter.get_input_details()[0]\n",
        "o_details = tfl_inter.get_output_details()[0]\n",
        "\n",
        "i_quant = i_details[\"quantization_parameters\"]\n",
        "o_quant = o_details[\"quantization_parameters\"]\n",
        "i_scale      = i_quant['scales'][0]\n",
        "i_zero_point = i_quant['zero_points'][0]\n",
        "o_scale      = o_quant['scales'][0]\n",
        "o_zero_point = o_quant['zero_points'][0]\n",
        "\n",
        "def classify(i_data, o_value):\n",
        "  input_data = i_value.reshape((1, 32, 32, 3))\n",
        "  i_value_f32 = tf.dtypes.cast(input_data, tf.float32)\n",
        "  \n",
        "  # Quantize (float -> 8-bit) the input (check if input layer is 8-bit, first)\n",
        "  i_value_f32 = i_value_f32 / i_scale + i_zero_point\n",
        "  i_value_s8 = tf.cast(i_value_f32, dtype=tf.int8)\n",
        "\n",
        "  tfl_inter.set_tensor(i_details[\"index\"], i_value_s8)\n",
        "  tfl_inter.invoke()\n",
        "  o_pred = tfl_inter.get_tensor(o_details[\"index\"])[0]\n",
        "\n",
        "  return (o_pred - o_zero_point) * o_scale\n",
        "\n",
        "num_correct_samples = 0\n",
        "num_total_samples   = len(list(test_imgs))\n",
        "\n",
        "for i_value, o_value in zip(test_imgs, test_lbls):\n",
        "  o_pred_f32 = classify(i_value, o_value)\n",
        "  if np.argmax(o_pred_f32) == o_value:\n",
        "    num_correct_samples += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp3jzDk2Z4jK"
      },
      "source": [
        "### Print the accuracy of the quantized TFLite model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Il7-UAMAZ44C"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy:\", num_correct_samples/num_total_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NODqR0NIjkZ"
      },
      "outputs": [],
      "source": [
        "!apt-get update && apt-get -qq install xxd\n",
        "!xxd -i cifar10.tflite > model.h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kwlgTlBhyoR"
      },
      "source": [
        "## Converting a NumPy image to a C-byte array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js9A3b1Zh-Be"
      },
      "source": [
        "### Write a function to convert a 1D NumPy array of np.int8 values into a single string of integer values comma-separated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLdIRDAe8TMy"
      },
      "outputs": [],
      "source": [
        "def array_to_str(data):\n",
        "    NUM_COLS = 12\n",
        "    val_string = ''\n",
        "    for i, val in enumerate(data):\n",
        "        val_string += str(val)\n",
        "\n",
        "        if (i + 1) < len(data):\n",
        "            val_string += ','\n",
        "        if (i + 1) % NUM_COLS == 0:\n",
        "            val_string += '\\n'\n",
        "    return val_string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w80MZdtpiFy9"
      },
      "source": [
        "### Write a function to generate a C header file containing the input image stored in an int8_t array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpD54bb65whM"
      },
      "outputs": [],
      "source": [
        "def gen_h_file(size, data, ilabel):\n",
        "  str_out = f'int8_t g_test[] = '\n",
        "  str_out += \"\\n{\\n\"\n",
        "  str_out += f'{data}'\n",
        "  str_out += '};\\n'\n",
        "  str_out += f\"const int g_test_len = {size};\\n\"\n",
        "  str_out += f\"const int g_test_ilabel = {ilabel};\\n\"\n",
        "  return str_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KukSNltjjpQF"
      },
      "source": [
        "### Create a Pandas data frame from the CIFAR-10 test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPMPJ90VjzEE"
      },
      "outputs": [],
      "source": [
        "imgs = list(zip(test_imgs, test_lbls))\n",
        "cols = ['Image', 'Label']\n",
        "df = pd.DataFrame(imgs, columns = cols) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHr5BwAgj1YT"
      },
      "source": [
        "### Get only ship images from the Pandas data frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbZi4z5JkH5_"
      },
      "outputs": [],
      "source": [
        "cond = df['Label'] == 8\n",
        "ship_samples = df[cond]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9Vi9nVRj9vx"
      },
      "source": [
        "### Iterate over the ship images and run the inference. Convert the image that returns \"ship\" to C-byte array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgswci5Uyb3_"
      },
      "outputs": [],
      "source": [
        "c_code = \"\"\n",
        "\n",
        "for index, row in ship_samples.iterrows():\n",
        "  i_value = np.asarray(row['Image'].tolist())\n",
        "  o_value = np.asarray(row['Label'].tolist())\n",
        "  o_pred_f32 = classify(i_value, o_value)\n",
        "  if np.argmax(o_pred_f32) == o_value:\n",
        "    i_value_f32 = i_value / i_scale + i_zero_point\n",
        "    i_value_s8  = i_value_f32.astype(dtype=np.uint8)\n",
        "    i_value_s8  = i_value_s8.ravel()\n",
        "\n",
        "    # Generate a string from NumPy array\n",
        "    val_string = array_to_str(i_value_s8)\n",
        "\n",
        "    c_code = gen_h_file(i_value_s8.size, val_string, \"8\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oP_rTTuJlFB5"
      },
      "source": [
        "### Save the generated image in the input.h file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2PUCsSDlJn-"
      },
      "outputs": [],
      "source": [
        "with open(\"input.h\", 'w') as file:\n",
        "  file.write(c_code)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "chapter07.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
